#!/usr/bin/env python3
"""
í–…í‹± íŒ¨í„´ JSON ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (3ê°€ì§€ ëª¨ë“œìš©)

ëŒ€ìƒ íŠ¸ë™:
- sleep_03: ê¹Šì€ ë°¤ì˜ ê¿ˆ (Deep Sleep - Heartbeat)
- separation_01: ë¬µì§í•œ ìœ„ë¡œ (Calm Shelter - Heartbeat)
- senior_02: ê¹Šì€ ì•ˆì • (Senior Care - Purr)
"""

from pathlib import Path
from mido import MidiFile
import json

# General MIDI ì•…ê¸° ë§¤í•‘
GM_INSTRUMENTS = {
    0: "Acoustic Grand Piano", 42: "Cello", 43: "Contrabass",
    32: "Acoustic Bass", 33: "Electric Bass (finger)", 34: "Electric Bass (pick)",
}

# í–…í‹± ëŒ€ìƒ íŠ¸ë™ ì„¤ì •
HAPTIC_TRACKS = {
    'sleep_03': {
        'title': 'ê¹Šì€ ë°¤ì˜ ê¿ˆ',
        'folder': '1_3_ê¹Šì€ ë°¤ì˜ ê¿ˆ',
        'pattern': 'heartbeat',
        'target_instruments': ['Cello', 'Contrabass'],
    },
    'separation_01': {
        'title': 'ë¬µì§í•œ ìœ„ë¡œ',
        'folder': '2_1_ë¬µì§í•œ ìœ„ë¡œ',
        'pattern': 'heartbeat',
        'target_instruments': ['Cello', 'Contrabass'],
    },
    'senior_02': {
        'title': 'ê¹Šì€ ì•ˆì •',
        'folder': '5_2_ê¹Šì€ ì•ˆì •',
        'pattern': 'purr',
        'target_instruments': ['Contrabass', 'Cello'],
    },
}


def ticks_to_ms(ticks, ticks_per_beat, tempo_us):
    """Ticksë¥¼ ë°€ë¦¬ì´ˆë¡œ ë³€í™˜"""
    return int((ticks * tempo_us) / (ticks_per_beat * 1000))


def extract_haptic_events(midi_path, config):
    """MIDIì—ì„œ í–…í‹± ì´ë²¤íŠ¸ ì¶”ì¶œ"""
    midi = MidiFile(midi_path)
    
    # í…œí¬ ì¶”ì¶œ (ì²« ë²ˆì§¸ set_tempo)
    tempo_us = 500000  # ê¸°ë³¸ 120 BPM
    for track in midi.tracks:
        for msg in track:
            if msg.type == 'set_tempo':
                tempo_us = msg.tempo
                break
        if tempo_us != 500000:
            break
    
    bpm = round(60_000_000 / tempo_us, 1)
    
    # ê° íŠ¸ë™ë³„ë¡œ ì•…ê¸°ì™€ ë…¸íŠ¸ ì¶”ì¶œ
    events = []
    
    for track_idx, track in enumerate(midi.tracks):
        current_time_ticks = 0
        track_instrument = None
        
        for msg in track:
            current_time_ticks += msg.time
            
            # Program Changeë¡œ ì•…ê¸° í™•ì¸
            if msg.type == 'program_change':
                track_instrument = GM_INSTRUMENTS.get(msg.program, f"Program{msg.program}")
            
            # Note On ì´ë²¤íŠ¸ ì²˜ë¦¬
            if msg.type == 'note_on' and msg.velocity > 0:
                # íƒ€ê²Ÿ ì•…ê¸°ë§Œ
                if track_instrument not in config['target_instruments']:
                    continue
                
                # ì €ìŒì—­ë§Œ (C2=36 ~ C4=60)
                if not (36 <= msg.note <= 60):
                    continue
                
                time_ms = ticks_to_ms(current_time_ticks, midi.ticks_per_beat, tempo_us)
                
                events.append({
                    'time': time_ms,
                    'note': msg.note,
                    'velocity': msg.velocity,
                })
    
    # ì‹œê°„ìˆœ ì •ë ¬
    events.sort(key=lambda x: x['time'])
    
    # í†µê³„ ê³„ì‚°
    velocities = [e['velocity'] for e in events]
    notes = [e['note'] for e in events]
    
    stats = {
        'total_events': len(events),
        'duration_ms': events[-1]['time'] if events else 0,
        'avg_velocity': round(sum(velocities) / len(velocities)) if velocities else 0,
        'note_range': f"{min(notes)}-{max(notes)}" if notes else "N/A",
    }
    
    return {
        'bpm': bpm,
        'events': events,
        'stats': stats,
    }


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    project_root = Path(__file__).parent.parent
    sound_dir = project_root / 'assets' / 'sound'
    output_dir = project_root / 'assets' / 'haptic_patterns'
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("ğŸµ í–…í‹± íŒ¨í„´ JSON ìƒì„± ì¤‘...\n")
    
    results = {}
    
    for track_id, config in HAPTIC_TRACKS.items():
        print(f"ğŸ“ {track_id}: {config['title']}")
        
        # Orchestrated MIDI íŒŒì¼ ì°¾ê¸°
        track_folder = sound_dir / config['folder']
        orch_files = list(track_folder.glob('*Orchestrated.mid'))
        
        if not orch_files:
            print(f"   âš ï¸  Orchestrated.mid íŒŒì¼ ì—†ìŒ\n")
            continue
        
        # í–…í‹± ì´ë²¤íŠ¸ ì¶”ì¶œ
        result = extract_haptic_events(orch_files[0], config)
        
        # JSON ë°ì´í„° êµ¬ì„±
        json_data = {
            'track_id': track_id,
            'title': config['title'],
            'haptic_enabled': True,
            'pattern': config['pattern'],
            'bpm': result['bpm'],
            'events': result['events'],
            'stats': result['stats'],
        }
        
        # JSON íŒŒì¼ ì €ì¥
        output_file = output_dir / f"{track_id}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        
        print(f"   âœ… {result['stats']['total_events']}ê°œ ì´ë²¤íŠ¸ ìƒì„±")
        print(f"   ğŸ“Š BPM: {result['bpm']}, í‰ê·  Velocity: {result['stats']['avg_velocity']}")
        print(f"   ğŸ’¾ ì €ì¥: {output_file.name}\n")
        
        results[track_id] = json_data
    
    print(f"{'='*60}")
    print("âœ… ì™„ë£Œ!")
    print(f"ì´ {len(results)}ê°œ í–…í‹± íŒ¨í„´ JSON ìƒì„±")
    print(f"ì¶œë ¥ ê²½ë¡œ: {output_dir}")


if __name__ == '__main__':
    main()
